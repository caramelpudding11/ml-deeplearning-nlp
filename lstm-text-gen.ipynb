{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2023-08-22T06:32:04.865376Z","iopub.status.busy":"2023-08-22T06:32:04.865034Z","iopub.status.idle":"2023-08-22T06:32:09.924034Z","shell.execute_reply":"2023-08-22T06:32:09.923033Z","shell.execute_reply.started":"2023-08-22T06:32:04.865342Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-09-10 01:35:06.403601: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-09-10 01:35:06.432483: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-09-10 01:35:06.634283: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-09-10 01:35:06.635681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-09-10 01:35:07.646639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import tensorflow.keras.utils \n","import tensorflow as tf\n","import numpy as np \n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:09.931780Z","iopub.status.busy":"2023-08-22T06:32:09.929427Z","iopub.status.idle":"2023-08-22T06:32:10.480173Z","shell.execute_reply":"2023-08-22T06:32:10.478741Z","shell.execute_reply.started":"2023-08-22T06:32:09.931736Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataline</th>\n","      <th>Play</th>\n","      <th>PlayerLinenumber</th>\n","      <th>ActSceneLine</th>\n","      <th>Player</th>\n","      <th>PlayerLine</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Henry IV</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ACT I</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Henry IV</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SCENE I. London. The palace.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Henry IV</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Henry IV</td>\n","      <td>1.0</td>\n","      <td>1.1.1</td>\n","      <td>KING HENRY IV</td>\n","      <td>So shaken as we are, so wan with care,</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Henry IV</td>\n","      <td>1.0</td>\n","      <td>1.1.2</td>\n","      <td>KING HENRY IV</td>\n","      <td>Find we a time for frighted peace to pant,</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n","0         1  Henry IV               NaN          NaN            NaN   \n","1         2  Henry IV               NaN          NaN            NaN   \n","2         3  Henry IV               NaN          NaN            NaN   \n","3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n","4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n","\n","                                          PlayerLine  \n","0                                              ACT I  \n","1                       SCENE I. London. The palace.  \n","2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n","3             So shaken as we are, so wan with care,  \n","4         Find we a time for frighted peace to pant,  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('Shakespeare_data.csv', nrows = 50000)\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:10.497303Z","iopub.status.busy":"2023-08-22T06:32:10.496587Z","iopub.status.idle":"2023-08-22T06:32:10.962857Z","shell.execute_reply":"2023-08-22T06:32:10.961696Z","shell.execute_reply.started":"2023-08-22T06:32:10.497252Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["50000\n","['ACT I', 'SCENE I. London. The palace.', 'Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others']\n"]}],"source":["import csv\n","\n","corpus = []\n","\n","with open('Shakespeare_data.csv') as f:\n","    reader = csv.reader(f, delimiter=',')\n","    next(reader)        # to pass first row,header\n","    for row in reader:\n","        corpus.append(row[5])\n","\n","corpus = corpus[:50000]       \n","print(len(corpus))\n","print(corpus[:3])\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:10.964677Z","iopub.status.busy":"2023-08-22T06:32:10.964230Z","iopub.status.idle":"2023-08-22T06:32:11.896507Z","shell.execute_reply":"2023-08-22T06:32:11.895532Z","shell.execute_reply.started":"2023-08-22T06:32:10.964616Z"},"trusted":true},"outputs":[],"source":["import string\n","\n","def text_cleaner(text):\n","    text = \"\".join(car for car in text if car not in string.punctuation).lower()\n","    text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n","    return text\n","\n","corpus = [text_cleaner(line) for line in corpus[:50000]]\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:11.900673Z","iopub.status.busy":"2023-08-22T06:32:11.900372Z","iopub.status.idle":"2023-08-22T06:32:11.996336Z","shell.execute_reply":"2023-08-22T06:32:11.995390Z","shell.execute_reply.started":"2023-08-22T06:32:11.900643Z"},"trusted":true},"outputs":[{"data":{"text/plain":["3759"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Tokenization is the process of splitting up a text into a list of individual words, or tokens.\n","# corpus is too big if you try with all data, you can see this message\n","corpus = corpus[:3000]\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(corpus)\n","word_index = tokenizer.word_index\n","total_words = len(word_index) + 1\n","total_words"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:11.998611Z","iopub.status.busy":"2023-08-22T06:32:11.998021Z","iopub.status.idle":"2023-08-22T06:32:12.217070Z","shell.execute_reply":"2023-08-22T06:32:12.216066Z","shell.execute_reply.started":"2023-08-22T06:32:11.998569Z"},"trusted":true},"outputs":[],"source":["# create input sequences using list of tokens\n","input_sequences =[]\n","\n","for sentence in corpus:\n","    token_list = tokenizer.texts_to_sequences([sentence])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:12.220816Z","iopub.status.busy":"2023-08-22T06:32:12.220525Z","iopub.status.idle":"2023-08-22T06:32:12.490442Z","shell.execute_reply":"2023-08-22T06:32:12.489580Z","shell.execute_reply.started":"2023-08-22T06:32:12.220787Z"},"trusted":true},"outputs":[],"source":["# pad sequences \n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, \n","                                         maxlen=max_sequence_len, \n","                                         padding='pre'))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:12.493597Z","iopub.status.busy":"2023-08-22T06:32:12.492998Z","iopub.status.idle":"2023-08-22T06:32:12.576730Z","shell.execute_reply":"2023-08-22T06:32:12.575785Z","shell.execute_reply.started":"2023-08-22T06:32:12.493554Z"},"trusted":true},"outputs":[],"source":["# create predictors and label\n","predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","# create one-hot encoding of the labels\n","label = tensorflow.keras.utils.to_categorical(label, num_classes=total_words)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:12.578820Z","iopub.status.busy":"2023-08-22T06:32:12.578420Z","iopub.status.idle":"2023-08-22T06:32:12.586956Z","shell.execute_reply":"2023-08-22T06:32:12.586077Z","shell.execute_reply.started":"2023-08-22T06:32:12.578777Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 0. 0. ... 0. 0. 0.]\n","(3759,)\n"]}],"source":["print(label[0])\n","print(label[0].shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:32:12.589155Z","iopub.status.busy":"2023-08-22T06:32:12.588453Z","iopub.status.idle":"2023-08-22T06:32:15.564040Z","shell.execute_reply":"2023-08-22T06:32:15.563299Z","shell.execute_reply.started":"2023-08-22T06:32:12.589115Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 29, 10)            37590     \n","                                                                 \n"," bidirectional (Bidirection  (None, 200)               88800     \n"," al)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 200)               0         \n","                                                                 \n"," dense (Dense)               (None, 3759)              755559    \n","                                                                 \n","=================================================================\n","Total params: 881949 (3.36 MB)\n","Trainable params: 881949 (3.36 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["model = Sequential()\n","model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(100)))\n","model.add(Dropout(0.3))\n","model.add(Dense(total_words, activation='relu'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":12,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-08-22T06:32:15.566724Z","iopub.status.busy":"2023-08-22T06:32:15.566111Z","iopub.status.idle":"2023-08-22T06:46:25.099305Z","shell.execute_reply":"2023-08-22T06:46:25.098496Z","shell.execute_reply.started":"2023-08-22T06:32:15.566683Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","628/628 [==============================] - 10s 13ms/step - loss: 0.0241 - accuracy: 0.0285\n","Epoch 2/5\n","628/628 [==============================] - 8s 12ms/step - loss: 0.0021 - accuracy: 0.0294\n","Epoch 3/5\n","628/628 [==============================] - 8s 12ms/step - loss: 0.0020 - accuracy: 0.0301\n","Epoch 4/5\n","628/628 [==============================] - 8s 12ms/step - loss: 0.0021 - accuracy: 0.0292\n","Epoch 5/5\n","628/628 [==============================] - 8s 12ms/step - loss: 0.0021 - accuracy: 0.0293\n"]}],"source":["history = model.fit(predictors, label, epochs=5,  verbose=1)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:47:34.214304Z","iopub.status.busy":"2023-08-22T06:47:34.213905Z","iopub.status.idle":"2023-08-22T06:47:34.332766Z","shell.execute_reply":"2023-08-22T06:47:34.332050Z","shell.execute_reply.started":"2023-08-22T06:47:34.214269Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["help me in this the the the the the the the the the the\n"]}],"source":["seed_text = \"help me in this\"\n","next_words = 10\n","\n","  \n","for _ in range(next_words):\n","    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predicted = model.predict(token_list, verbose=0)\n","    c = np.argmax(predicted, axis = 1)\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","        if index == c:\n","            output_word = word\n","            break\n","    seed_text += \" \" + output_word\n","    if len(seed_text) % 10 == 0 :\n","        seed_text+= '\\n'\n","print(seed_text)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T06:46:26.111788Z","iopub.status.busy":"2023-08-22T06:46:26.111504Z","iopub.status.idle":"2023-08-22T06:46:26.194606Z","shell.execute_reply":"2023-08-22T06:46:26.193666Z","shell.execute_reply.started":"2023-08-22T06:46:26.111759Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Love all, trust a few the the the the the the the the the the\n"]}],"source":["seed_text = \"Love all, trust a few\"\n","next_words = 10\n","\n","  \n","for _ in range(next_words):\n","    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predicted = model.predict(token_list, verbose=0)\n","    c = np.argmax(predicted, axis = 1)\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","        if index == c:\n","            output_word = word\n","            break\n","    seed_text += \" \" + output_word\n","    if len(seed_text) % 10 == 0 :\n","        seed_text+= '\\n'\n","print(seed_text)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Reloading Tuner from tuner_dir/lstm_sentiment/tuner0.json\n","INFO:tensorflow:Oracle triggered exit\n","Best Hyperparameters:\n","<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7f0ae0236710>\n","Epoch 1/5\n","502/502 [==============================] - 8s 13ms/step - loss: 6.8117 - accuracy: 0.0328 - val_loss: 6.7459 - val_accuracy: 0.0481\n","Epoch 2/5\n","502/502 [==============================] - 6s 12ms/step - loss: 6.3378 - accuracy: 0.0441 - val_loss: 6.7862 - val_accuracy: 0.0498\n","Epoch 3/5\n","502/502 [==============================] - 6s 12ms/step - loss: 6.1763 - accuracy: 0.0547 - val_loss: 6.8331 - val_accuracy: 0.0583\n","Epoch 4/5\n","502/502 [==============================] - 6s 12ms/step - loss: 6.0031 - accuracy: 0.0630 - val_loss: 6.7913 - val_accuracy: 0.0667\n","Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_6 (Embedding)     (None, 29, 32)            120288    \n","                                                                 \n"," lstm_6 (LSTM)               (None, 128)               82432     \n","                                                                 \n"," dropout_6 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 3759)              484911    \n","                                                                 \n","=================================================================\n","Total params: 687631 (2.62 MB)\n","Trainable params: 687631 (2.62 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["from kerastuner.tuners import RandomSearch\n","from kerastuner.engine.hyperparameters import HyperParameters\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","def build_model(hp):\n","    model = Sequential()\n","    model.add(Embedding(total_words, hp.Int('embedding_dim', min_value=32, max_value=128, step=32), input_length=max_sequence_len-1))\n","    model.add(LSTM(units=hp.Int('lstm_units', min_value=32, max_value=128, step=32), dropout=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n","    model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n","    model.add(Dense(total_words, activation=hp.Choice('dense_activation',values=['relu','sigmoid','softmax']),kernel_initializer='he_normal'))\n","    model.compile(optimizer='adam', loss=hp.Choice('loss_fn',values=['binary_crossentropy','categorical_crossentropy']), metrics=['accuracy'])\n","    return model\n","\n","# Initialize Keras Tuner RandomSearch\n","tuner = RandomSearch(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=5,\n","    directory='tuner_dir',\n","    project_name='lstm_sentiment'\n",")\n","\n","# Perform hyperparameter search\n","tuner.search(predictors, label, validation_split=0.2, epochs=3)\n","\n","# Get the best hyperparameters\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","print(\"Best Hyperparameters:\")\n","print(best_hps)\n","\n","# Build the final model with the best hyperparameters\n","model = tuner.hypermodel.build(best_hps)\n","model.fit(predictors, label, validation_split=0.2, epochs=5, callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n","model.summary()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Chosen embedding dimension: 32\n","Chosen number of LSTM units: 128\n","Chosen dropout rate: 0.0\n","Chosen Activation Function: softmax\n","Chosen Loss Function: categorical_crossentropy\n"]}],"source":["# Print the chosen activation function and loss function\n","best_activation = best_hps.get('dense_activation')\n","best_loss_function = best_hps.get('loss_fn')\n","best_em_dim = best_hps.get('embedding_dim')\n","best_units = best_hps.get('lstm_units')\n","best_dropout = best_hps.get('Dropout_rate')\n","print(\"Chosen embedding dimension:\", best_em_dim)\n","print(\"Chosen number of LSTM units:\", best_units)\n","print(\"Chosen dropout rate:\", best_dropout)\n","print(\"Chosen Activation Function:\", best_activation)\n","print(\"Chosen Loss Function:\", best_loss_function)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_5 (Embedding)     (None, 29, 10)            37590     \n","                                                                 \n"," bidirectional_3 (Bidirecti  (None, 200)               88800     \n"," onal)                                                           \n","                                                                 \n"," dropout_5 (Dropout)         (None, 200)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 3759)              755559    \n","                                                                 \n","=================================================================\n","Total params: 881949 (3.36 MB)\n","Trainable params: 881949 (3.36 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["model = Sequential()\n","model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(100)))\n","model.add(Dropout(0.3))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","628/628 [==============================] - 10s 12ms/step - loss: 6.7153 - accuracy: 0.0334\n","Epoch 2/5\n","628/628 [==============================] - 8s 12ms/step - loss: 6.3727 - accuracy: 0.0453\n","Epoch 3/5\n","628/628 [==============================] - 8s 12ms/step - loss: 6.2331 - accuracy: 0.0499\n","Epoch 4/5\n","628/628 [==============================] - 8s 12ms/step - loss: 6.1308 - accuracy: 0.0524\n","Epoch 5/5\n","628/628 [==============================] - 8s 12ms/step - loss: 6.0384 - accuracy: 0.0552\n"]}],"source":["history = model.fit(predictors, label, epochs=5,  verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["seed_text = \"help me in this\"\n","next_words = 10\n","\n","  \n","for _ in range(next_words):\n","    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predicted = model.predict(token_list, verbose=0)\n","    c = np.argmax(predicted, axis = 1)\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","        if index == c:\n","            output_word = word\n","            break\n","    seed_text += \" \" + output_word\n","    if len(seed_text) % 10 == 0 :\n","        seed_text+= '\\n'\n","print(seed_text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["seed_text = \"Love all, trust a few\"\n","next_words = 10\n","\n","  \n","for _ in range(next_words):\n","    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predicted = model.predict(token_list, verbose=0)\n","    c = np.argmax(predicted, axis = 1)\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","        if index == c:\n","            output_word = word\n","            break\n","    seed_text += \" \" + output_word\n","    if len(seed_text) % 10 == 0 :\n","        seed_text+= '\\n'\n","print(seed_text)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
